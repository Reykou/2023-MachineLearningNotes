# 2.3高级学习算法：应用机器学习的建议

復習: Done
日付: 2023年3月27日
最終更新日時: 2023年4月15日 19:39

# 应用机器学习的建议：**Advice for applying machine learning**

---

## 决定下一步尝试什么：[Deciding what to try next](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/ffdx5/deciding-what-to-try-next)

本视频主要讲述了如何在机器学习项目中**有效地使用各种学习算法，**包括线性回归、逻辑回归、神经网络等，并分享了一些关于如何在项目中做出好的决策的提示，以便更高效地建立机器学习系统。

- 当你在构建机器学习算法时，通常会有很多不同的尝试，如**增加训练样本、减少特征数量、添加新的特征等等，而要提高机器学习算法的效率，关键在于如何做出好的决策**。
    
    ![截屏2023-04-05 13.57.26.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_13.57.26.png)
    
- 本周视频将向大家介绍如何进行一系列的**诊断来检查学习算法的表现，如何评估学习算法的性能，并给出如何进行优化的指导。**同时，视频还将介绍不同的诊断工具，帮助你更好地了解算法的表现并进行优化。
    
    ![截屏2023-04-05 13.59.09.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_13.59.09.png)
    

*ˌdaɪəɡˈnɑstɪk*

> **一句话总结：**
优化机器学习可以调整很多参数。诊断 Diagnositc 所调整的参数是否有效，会为我们节省大量时间。
> 

## 评估一个模型：[Evaluating a model](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/26yGi/evaluating-a-model)

评估机器学习模型的性能是指了解模型在对新数据进行预测时的表现。

- 🔰**模型评估（Evaluating a model）**：衡量一个机器学习模型的性能。通过将预测值与实际值进行比较，可以得到一个衡量模型好坏的指标。
- 首先，可以绘制模型的曲线来直观地观察其性能。但是，当模型的特征增多时，绘制曲线变得困难，因此需要更加系统化的方法来评估模型的性能。一个常见的方法是将**训练数据集分为两个子集：训练集和测试集。在训练集上训练模型，然后在测试集上进行评估，计算出测试误差。**测试误差通常是通过计算**测试集上的平均误差来计算的**。
    
    ![截屏2023-04-05 14.04.01.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.04.01.png)
    
    ![截屏2023-04-05 14.04.11.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.04.11.png)
    
- 在进行线性回归时，我们通常使用**平方误差代价函数来最小化误差，同时还可以通过正则化项来避免过拟合。**需要注意的是，在计算测试误差时，正则化项是不包括在内的。除了测试误差，我们还可以计算训练误差，以衡量模型在训练集上的性能。
    - 🔰**平方误差代价（Squared error cost）**：平方误差代价是衡量模型预测值与实际值之间差异的一种方法。它计算了预测值与实际值之差的平方和。线性回归的目标是找到一组参数，使得这个平方误差代价最小化。
    
    ![截屏2023-04-05 14.04.36.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.04.36.png)
    
    ![截屏2023-04-05 14.04.52.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.04.52.png)
    
    ![截屏2023-04-05 14.05.03.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.05.03.png)
    
    ![截屏2023-04-05 14.05.28.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.05.28.png)
    

- 🔰训练误差（J train）：训练误差是指模型在训练集上的平均误差。在回归问题中，这通常表示为平方误差代价；在分类问题中，通常表示为逻辑损失。训练误差可以衡量模型在训练数据上的拟合程度。
- 🔰测试误差（J test）：测试误差是指模型在测试集上的平均误差。在回归问题中，这通常表示为平方误差代价；在分类问题中，通常表示为逻辑损失。测试误差可以衡量模型对新数据的泛化能力。

在分类问题中，**J test 和 J train 可以用来衡量模型在测试集和训练集上的分类正确率。**具体地，在测试集上，可以计算模型预测的分类与实际分类不一致的样本所占的比例；在训练集上，可以计算模型预测的分类与实际分类不一致的样本所占的比例。

- 🔰问题：我看J train 和J test 的公式完全一样啊，那评价标准是J train 和J test 约接近越好吗？
    
    是的，**J train（训练误差）和J test（测试误差）的计算公式确实是相同的，它们都衡量模型的误差。**不过，J train 是在训练集上计算的，而J test 是在测试集上计算的。这两个指标有不同的作用：
    
    - J train：**衡量模型在训练数据上的拟合程度，较低的训练误差意味着模型在训练数据上的拟合效果较好**。
    - J test：**衡量模型在测试数据上的泛化能力，较低的测试误差意味着模型在未见过的数据上的预测性能较好。**
    
    我们的目标是找到一个在训练集上拟合得足够好（较低的J train），同时在测试集上泛化能力强（较低的J test）的模型。如果J train 和J test 都很低，这意味着模型在训练集和测试集上的表现都很好，这是我们所希望的结果。
    
    然而，在实际情况中，有时会出现以下情况：
    
    - 过拟合（overfitting）：当模型在训练集上表现非常好（低J train），但在测试集上表现较差（高J test）时，说明模型过度拟合了训练数据，泛化能力较差。
    - 欠拟合（underfitting）：当模型在训练集和测试集上都表现较差（高J train 和高J test）时，说明模型没有很好地捕捉到数据中的模式，可能需要增加模型的复杂度或进行其他优化。
    
    因此，我们希望找到一个平衡点，使得J train 和J test 都相对较低，以获得一个既能拟合训练数据又具有良好泛化能力的模型。
    

> **一句话总结：**
评估模型可以把整个数据集三七分、test/train 、训练出来的模型在 2 个子训练集上误差都低、则效果越好。
平方误差代价函数：最小化误差，正则化避免过拟合
> 

## 模型选择和训练、交叉验证和选择[Model selection and training/cross validation/test sets](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/zqXm6/model-selection-and-training-cross-validation-test-sets)

这个视频主要讲解了**如何使用训练集、交叉验证集和测试集来进行模型选择**。在机器学习中，为了选择一个合适的模型，我们需要估计模型在未见过的数据上的泛化能力。下面是一些关键知识点：

- 划分数据集：将数据集分为三个子集，**训练集（training set）、交叉验证集（cross-validation set）和测试集（test set）**。
    
    ![截屏2023-04-05 14.35.53.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.35.53.png)
    
    ![截屏2023-04-05 14.36.07.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.36.07.png)
    
    ![截屏2023-04-05 14.36.44.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.36.44.png)
    
- 计算误差：
    - 训练误差（training error）：在训练集上计算模型的误差。
    - 交叉验证误差（cross-validation error）：在交叉验证集上计算模型的误差。也被称为验证误差（validation error）或开发集误差（development set error）。
    - 测试误差（test error）：在测试集上计算模型的误差。
        
        ![截屏2023-04-05 14.36.55.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.36.55.png)
        
- **模型选择：使用交叉验证集来评估不同模型的性能。选择交叉验证误差最小的模型作为最佳模型。**
    
    ![截屏2023-04-05 14.37.05.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.37.05.png)
    
- **估计泛化误差：在测试集上计算最佳模型的误差**，以得到对模型在未见过的数据上泛化能力的估计。
    
    ![截屏2023-04-05 14.37.19.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_14.37.19.png)
    

通过这种方法，可以在不同模型之间进行选择，例如线性回归中的多项式阶数，神经网络中的网络结构等。这个方法可以帮助我们自动选择在未见过的数据上表现最好的模型。

- 🔰问题：可以理解fwb 的表达式可以有很多种形式，神经元也可以有很多层、每层也可以定义的个数也不是在一开始根据什么原因固定不变的。最终只要是在cross-validation error的结果最小、那么就说这个模型是最佳的？
    
    是的，您的理解是正确的。**在机器学习中，我们可以尝试使用不同的模型表达式、神经网络结构（包括层数和每层神经元的个数）等。我们不能在一开始就知道哪种模型结构是最佳的，因此需要使用交叉验证来评估模型的性能。**
    
    通过计算不同模型在交叉验证集上的误差，我们可以选择交叉验证误差最小的模型作为最佳模型。这样，我们就能找到在新数据上泛化能力最强的模型。当然，为了避免过拟合和欠拟合的问题，我们还需要根据实际情况调整模型的复杂度。
    

> **一句话总结：**
划分数据集：训练集（training set）`**6**`、交叉验证集（cross-validation set）`**2**`和测试集（test set 泛化能力）`**2**`  → 计算各自的误差J(w,b)
模型选择：用交叉验证误差最小的模型
> 

## 测试[: Advice for applying machine learning](https://www.coursera.org/learn/advanced-learning-algorithms/exam/bURi8/practice-quiz-advice-for-applying-machine-learning)

![截屏2023-04-05 15.19.10.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_15.19.10.png)

### 作业

![截屏2023-04-05 15.28.25.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_15.28.25.png)

- 🔰问题：为什么选 2 呢？我们确实需要把所有数据分为三份，并训练。最终根据cross validation set 来判断啊？
    
    您的理解是正确的。在进行模型选择时，我们需要使用交叉验证集来评估不同模型的性能。这是**因为我们已经使用训练集来训练了这些模型，**所以评估它们在训练集上的性能会导致过度乐观的估计。同时，**测试集是为了在最终选定模型之后评估模型在未知数据上的泛化性能，因此在模型选择阶段不应使用测试集。**
    
    选项2（交叉验证集）是正确的选择。通过计算不同模型在交叉验证集上的误差，我们可以选择性能最佳的模型。这种方法可以帮助我们找到在新数据上具有更好泛化能力的模型，同时避免过拟合和欠拟合的问题。
    

![截屏2023-04-05 15.33.06.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-05_15.33.06.png)

- 答案：选项4（一种用于了解学习算法工作与否的测试）是正确的。在机器学习的背景下，诊断是一种方法，**可以帮助我们了解学习算法的哪些方面有效，哪些方面无效或需要改进。**通过运行诊断，我们可以获得关于算法性能的深入了解，**并找到可能的解决方案来优化算法**。
    
    以下是其他选项的解释：
    
    - 4-这个选项描述的是机器学习在医疗领域的应用，而不是机器学习中的诊断。
    - 3-这个选项涉及到尝试不同的方法来改进算法，但它没有强调通过诊断来了解算法的哪些方面需要改进。
    - 1-这个选项描述的是在测试集上评估学习算法的性能，而不是运行诊断来了解算法的工作原理。

---

# 偏见和方差：**Bias and variance**

## 诊断bias和variance：[Diagnosing bias and variance](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/L6SHx/diagnosing-bias-and-variance)

如何诊断机器学习算法的偏差（bias *ˈbaɪəs*）和方差（variance *ˈvɛriəns*），以及它们与模型性能之间的关系。以下是关键知识点：

- **偏差bias和方差variance**：**偏差表示模型对训练数据的拟合程度**，高偏差意味着欠拟合。**方差表示模型对新数据的泛化能力**，高方差意味着过拟合。
    
    ![截屏2023-04-06 19.46.12.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_19.46.12.png)
    
- 计算训练误差（J_train）和交叉验证误差（J_cv）：训练误差可以帮助诊断模型是否具有高偏差问题；交叉验证误差可以帮助诊断模型是否具有高方差问题。
    
    ![截屏2023-04-06 19.46.26.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_19.46.26.png)
    
- **高偏差的诊断：当训练误差（J_train）很高时，**表明模型具有高偏差问题，即欠拟合。
- **高方差的诊断：当交叉验证误差（J_cv）比训练误差（J_train）高很多时**，表明模型具有高方差问题，即过拟合。
- 在某些情况下，模型可能同时具有高偏差和高方差问题。在这种情况下，训练误差（J_train）较高，而交叉验证误差（J_cv）比训练误差（J_train）更高。
- 根据模型的偏差和方差诊断结果，可以采取相应的策略来优化模型性能。
    
    ![截屏2023-04-06 19.46.36.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_19.46.36.png)
    

通过诊断模型的偏差和方差问题，可以了解模型在训练数据和新数据上的表现，从而为优化模型提供有益的指导。

- 🔰问题：什么是偏差 什么是方差？是一种计算方式还是说预测y 与实际y 差距越大就是偏差、小就是方差吗？
    
    偏差（bias）和方差（variance）是用于衡量机器学习模型性能的两个重要概念。它们描述了模型在训练和预测过程中的两种不同类型的误差。
    
    1. **偏差（bias）：偏差是指模型的预测值与实际值之间的差距。**高偏差意味着模型无法很好地拟合**训练数据**，这通常是因为模型过于简单或者欠拟合。换句话说，模型没有学到数据中的基本模式，导致预测结果与实际结果相差较大。
    2. **方差（variance）：方差是指模型在不同数据集上的预测结果之间的差异。**高方差意味着模型对训练数据的拟合过于敏感，这通常是因为模型过于复杂或者过拟合。换句话说，模型学到了数据中的噪声和细节，而非数据的基本模式，导致模型在新的数据集上的泛化能力较差。
    
    偏差和方差是机器学习中的误差来源，它们不是计算方式，而是描述模型预测性能的指标。我们通常希望找到一个平衡点，在偏差和方差之间取得折中，以获得最佳的模型性能。这种折中被称为偏差-方差权衡（bias-variance tradeoff）。
    

> **一句话总结：**
Bias-用训练集是与实际值的差距：Jtran 高（Bias underfit）。
Variance-不同训练集与实际的差距。Jtran  <<Jcv 高（Variance /overfit）
> 

## 正则化和偏差（bias）和方差（variance）：[Regularization and bias/variance](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/JQZRO/regularization-and-bias-variance)

这个视频讲解了如何通过正则化，特别是选择**正则化参数 Lambda（λ）来影响学习算法的偏差和方差，从而改变整体性能。**以下是关键知识点：

- 选择不同的 Lambda 值会影响模型的偏差和方差。**较大的 Lambda 值会导致较高的bias（欠拟合），较小的 Lambda 值会导致较高的variance（过拟合）**。
    
    ![截屏2023-04-06 20.14.01.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_20.14.01.png)
    
- 使用交叉验证选择合适的 Lambda 值。**通过在多个 Lambda 值上训练模型并计算交叉验证误差 J_cv，可以选择使 J_cv 最小的 Lambda 值。**
    
    ![截屏2023-04-06 20.14.14.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_20.14.14.png)
    
- 观察训练误差 J_train 和交叉验证误差 J_cv 如何随着 Lambda 的变化而变化。较小的 Lambda 值会导致低训练误差和高交叉验证误差（高方差，过拟合），而较大的 Lambda 值会导致高训练误差和高交叉验证误差（高偏差，欠拟合）。在这两者之间存在一个最优的 Lambda 值，使得模型在偏差和方差之间取得平衡，从而获得最佳的性能。
    
    ![截屏2023-04-06 20.14.26.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_20.14.26.png)
    

了解如何根据训练误差 J_train 和交叉验证误差 J_cv 来判断模型的偏差和方差程度非常重要。在后续视频中，将进一步讨论如何通过建立学习算法的基线性能来判断 J_train 和 J_cv 的高低，并更好地诊断算法的问题。

> **一句话总结：**
正则化与 bias/variance 的关系。r 越大→Bias underfit 、r 越小→Variance /overfit。
选择 J_cv比较小的。
> 

## 建立基线：[Establishing a baseline level of performance](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/acyFT/establishing-a-baseline-level-of-performance)

如何判断学习算法是否存在高偏差（high bias）或高方差（high variance）问题。

- 以语音识别为例，**我们使用了训练错误（training error）和交叉验证错误（cross-validation error）来评估算法的性能。**但是，仅依赖这两个错误率可能无法准确判断算法是否存在高偏差或高方差问题，因此我们需要建立一个**基线性能（baseline level of performance）作为参考**。通常，人类水平的性能可以作为基线性能，因为人类在处理非结构化数据（如音频、图像和文本）方面非常擅长。
    
    ![截屏2023-04-06 20.39.02.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_20.39.02.png)
    
    ![截屏2023-04-06 20.39.08.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_20.39.08.png)
    

为了判断算法是否存在高偏差或高方差问题，我们需要关注以下两个关键量：

- 训练错误与基线性能之间的差距：如果这个差距很大，说明算法存在高偏差问题。
- 训练错误与交叉验证错误之间的差距：如果这个差距很大，说明算法存在高方差问题。
    
    ![截屏2023-04-06 21.20.18.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_21.20.18.png)
    

通过比较这些差距，我们可以得出算法在偏差和方差方面的问题。需要注意的是，有时候算法可能同时存在高偏差和高方差问题。

- 🔰问题：那如果只有这三种结果，是不是第二种情况是最优选择呢？
    
    在这三种情况下，**我们无法简单地根据这些错误率来判断哪种情况是最优选择**。这些错误率只能帮助我们了解算法在偏差和方差方面的问题，但并不能直接评价算法的综合性能。实际上，这些情况下的算法可能都需要进一步优化，以降低偏差和/或方差。
    
    对于**第一种情况（高方差），可以尝试增加训练数据量、减小模型复杂度、使用正则化方法或降低特征数量来减小方差。**对于**第二种情况（高偏差），可以尝试增加模型复杂度、增加特征数量或使用更复杂的算法来减小偏差。**对于第三种情况（高偏差、高方差），需要同时考虑降低偏差和方差的方法，可能需要在模型复杂度、训练数据量等方面进行权衡。
    

> **一句话总结：**
设置错误基线(你想得到什么结果)-人类。
判断：J_traing error 高→Bias underfit，  J_cv error 高→Variance /overfit
> 

## 学习曲线：[Learning curves](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/X8i9Z/learning-curves)

主要讨论了**学习曲线、偏差和方差，以及如何使用这些概念来诊断和优化机器学习算法**。以下是关键知识点的总结：

- **学习曲线**：学习曲线是一种图形工具，用于展示机器学习算法在不同训练集大小下的表现。**横轴表示训练集大小，纵轴表示误差**（训练误差或交叉验证误差）。
    
    ![截屏2023-04-06 21.28.12.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_21.28.12.png)
    
- 偏差和方差：
    - 高偏差（欠拟合）：算法对训练数据的拟合能力较弱，可能需要更复杂的模型或更多特征。学习曲线中，训练误差和交叉验证误差会随着训练集大小的增加而趋于平稳，且二者之间的差距较小。
        
        ![截屏2023-04-06 21.28.24.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_21.28.24.png)
        
    - 高方差（过拟合）：算法对训练数据的拟合能力过强，导致泛化能力较弱。学习曲线中，训练误差相对较低，而交叉验证误差较高，二者之间存在较大差距。
        
        ![截屏2023-04-06 21.28.43.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_21.28.43.png)
        
- 如何利用学习曲线优化算法：
    - **对于高偏差情况，增加模型复杂度、增加特征数量或使用更复杂的算法。**仅增加训练数据量对改善算法性能帮助不大。
    - **对于高方差情况，增加训练数据量、减小模型复杂度、使用正则化方法或降低特征数量。**在这种情况下，增加训练数据量可能会显著改善算法性能。

通过以上概念和方法，我们可以更好地理解和诊断机器学习算法在不同训练集大小下的表现，从而采取相应的措施来优化算法，降低偏差和/或方差，提高算法的泛化能力。

> **一句话总结：**
learning curve : 学习曲线误差-训练数据、
high bias 数据增加影响不大，应该用其他方式优化。
high variance 随着数据增大、是可能优化的。
> 

## 决定下次尝试什么：[Deciding what to try next revisited](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/WbRtr/deciding-what-to-try-next-revisited)

根据学习算法的问题（高偏差或高方差），可以采取以下策略进行优化：

- 高偏差 **high bias** 问题的解决方法：
    1. **添加更多特征**：这有助于为模型提供更多信息，以捕捉数据中的结构。
    2. **添加多项式特征**：这可以使模型更复杂，更好地适应数据。
    3. **减小正则化参数 Lambda**：这将使模型更关注拟合训练数据，从而减少偏差。
- 高方差 **high variance** 问题的解决方法：
    1. **获取更多训练数据**：这有助于减轻过拟合问题，提高模型的泛化能力。
    2. **尝试减少特征数量**：这将限制模型的复杂性，降低过拟合的风险。
    3. **增大正则化参数 Lambda**：这将迫使模型拟合更平滑、更简单的函数，以减少过拟合。

![截屏2023-04-06 22.03.40.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_22.03.40.png)

> **一句话总结：**
high bias ：增加 featurs, 增加参数复杂度，减少正则化参数lambda
high variance：增加 Training examples、减少featurs、增大正则化参数 lambda
> 

## 偏差、方差和神经网络：[Bias/variance and neural networks](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/d1EGK/bias-variance-and-neural-networks)

本视频**讲解了神经网络如何解决偏差和方差的问题**。首先，回顾了偏差和方差的概念，以及在模型选择中需要在二者之间进行权衡。然后，介绍了神经网络如何提供一种方法来解决这种权衡问题。这里是一些关键知识点：

- **大型神经网络在小型或中等规模数据集上训练时具有低偏差 bias。**这意味着，只要训练集不是特别庞大，那么通过增大神经网络的规模，可以适应训练集中的复杂模式，从而降低偏差。
    
    ![截屏2023-04-06 22.15.08.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_22.15.08.png)
    
- 一个简单的神经网络训练策略是：
    - 在**训练集上训练模型**并检查模型在训练集上的性能。如果性能不佳，表明存在高偏差问题，可以通过增大神经网络的规模来降低偏差。
    - **如果模型在训练集上的性能良好，检查其在交叉验证集上的性能。如果性能不佳，表明存在高方差问题，可以通过增加训练数据来降低方差**。
    
    ![截屏2023-04-06 22.15.18.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_22.15.18.png)
    
- 训练大型神经网络可能会变得计算密集型，因此需要强大的硬件，如 GPU。此外，收集更多数据可能受到一定限制。
- 一个更大的神经网络，只要经过适当的正则化，通常会比一个更小的网络性能更好。正则化可以通过在损失函数中添加权重衰减项来实现，以降低模型复杂度和过拟合风险。
    
    ![截屏2023-04-06 22.15.24.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_22.15.24.png)
    
- 在这个例子中，代码演示了如何在 **TensorFlow** 中实现未正则化的 MNIST 模型以及正则化的 MNIST 模型。在正则化的模型中，是的，我们需要**手动指定 Lambda 值（正则化参数）**。
    
    ![截屏2023-04-06 22.15.33.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_22.15.33.png)
    

总结：一个更大的神经网络在性能上通常不会受到损害，只要经过适当的正则化。然而，训练一个更大的神经网络可能会增加计算成本。此外，由于神经网络通常具有较低的偏差，训练神经网络时，往往需要关注解决方差问题。

- 🔰问题：也就是说、如果忽略成本、任何问题只要有更大的神经网络、有更多的数据、我们总会得到一个比较好的结果？！ 哇哦
    
    是的，如果忽略计算成本和数据收集的限制，使用更大的神经网络和更多的数据通常可以帮助我们获得更好的结果。
    

> **一句话总结：**
神经网络解决高偏差和高方差问题：
训练集高偏差：增加神经网络的复杂性
→测试集高方差：增加训练数据
TensorFlow 指定正则化参数：**`layer_1 = Dense(units=25,activation=’relu’, kernel_regularizer=L2(0.02))`**
> 

## [Optional Lab: Diagnosing Bias and Variance](https://www.coursera.org/learn/advanced-learning-algorithms/ungradedLab/CSsd4/optional-lab-diagnosing-bias-and-variance)

****Try smaller sets of features****

![截屏2023-04-06 22.52.40.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_22.52.40.png)

****Get more training examples****

![截屏2023-04-06 22.52.57.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_22.52.57.png)

# 机器学习开发过程：**Machine learning development process**

---

## ML 开发的循环迭代：[Iterative loop of ML development](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/uOXJM/iterative-loop-of-ml-development)

迭代 Iterative *ˈɪdəˌreɪdɪv*

课程讲解了如何开发一个机器学习系统的过程，并强调了在机器学习开发过程中需要做出决策的重要性。主要包括以下几个关键知识点：

- **机器学习开发的迭代循环：**
    - **确定系统的整体架构**：选择机器学习模型、决定使用的数据、选择超参数等。
    - **实现并训练模型**：首次训练的模型通常无法达到理想的性能。
    - **实施诊断**：检查算法的偏差和方差，以及进行错误分析（将在下一个视频中介绍）。
    - **基于诊断的洞察，决定是否需要调整模型，**如增加神经网络的大小、更改正则化参数 Lambda、增加数据量、增加或减少特征等。
    - 根据新的架构选择**，重新进行迭代，直到达到理想的性能。**
    
    ![截屏2023-04-06 23.01.07.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_23.01.07.png)
    
- 以电子邮件垃圾邮件分类器为例：
    - 使用监督学习算法，输入特征 x 为电子邮件的特征，输出标签 y 为 1（垃圾邮件）或 0（非垃圾邮件）。
    - 文本分类：将电子邮件文档分类为垃圾邮件或非垃圾邮件。
    - 构造电子邮件的特征：例如，使用前 10,000 个英语单词作为特征 x_1、x_2 到 x_10,000。特征值为 0 或 1，表示单词是否出现在电子邮件中。
        
        ![截屏2023-04-06 23.01.13.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_23.01.13.png)
        
        ![截屏2023-04-06 23.01.19.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_23.01.19.png)
        
- 改进学习算法：
    - 收集更多数据：例如，通过创建大量假电子邮件地址并将其传播到垃圾邮件发送者手中，收集大量垃圾邮件数据。
    - 开发基于电子邮件路由的复杂特征：根据电子邮件在不同服务器、不同网络之间传输的路径，判断是否为垃圾邮件。
    - 从电子邮件正文中提取更复杂数字特征：例如，将类似的单词视为相同的单词，或检测拼写错误和故意拼写错误的单词。
        
        ![截屏2023-04-06 23.01.28.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_23.01.28.png)
        
- 选择最有前景的方向：
    - 如果算法具有高偏差而非高方差，那么花费数月时间收集更多数据可能不是最有效的途径。如果算法具有高方差，那么收集更多数据可能会有很大帮助。
    - 在机器学习开发的迭代循环过程中，通过不同的诊断方法来指导模型或数据等架构选择的决策，从而确定哪些方向可能是值得尝试的。
        
        ![截屏2023-04-06 23.01.34.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_23.01.34.png)
        

> **一句话总结：**
机器学习的循环迭代集决策：确定系统的整体架构、实现并训练模型、实施诊断、决定是否需要调整模型、重新进行迭代直到达到理想的性能。
> 

## 误差分析：[Error analysis](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/FaPgS/error-analysis)

错误分析（Error Analysis *əˈnæləsəs*）过程，这是一种用于评估模型性能并找出需要改进的方面的方法。

- 错误分析的关键步骤如下：
    - 从开发集（Dev Set）中选择一组错误分类的样本（**被错误分类的样本中随机抽取一个子集，**不是所有样本中抽取）。
    - **分析这些错误分类的样本，尝试找出它们的共同特征或规律**。
    - 根据**错误分析的结果，提出假设并尝试改进模型**。
    - 测试**改进的模型，观察性能是否有所提高**。
    - 如果性能有所提高，继续进行错误分析和改进；如果没有提高，尝试其他假设。
    
    ![截屏2023-04-06 23.19.14.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_23.19.14.png)
    
- 通**过错误分析，你可以了解哪些类型的错误更为常见，并据此确定哪些方向更值得关注**。例如，如果发现许多错误都是药品垃圾邮件，你可能会考虑收集更多药品垃圾邮件的数据，或者设计与药品名字相关的特征。同样，如果发现钓鱼邮件是常见的问题，你可以尝试检查邮件中的URL并提取相关特征，或者针对性地收集更多钓鱼邮件的数据。
    
    ![截屏2023-04-06 23.19.29.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-06_23.19.29.png)
    

> **一句话总结：**
错误分析的步骤 Error Analysis：分析一个小的随机子集的数据、找到错误结果的共同特征或规律、提出改善假设、改进模型再次观察
> 

## 添加数据：[Adding data](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/AHAJy/adding-data)

本视频主要讨论了如何为机器学习应用添加或收集更多数据，以及在某些情况下创建更多数据。以下是关键知识点：

- 针对性地添加数据：在进行错误分析后，**根据结果找出算法表现不佳的数据子集，并针对性地收集更多此类数据，**而非收集所有类型的数据。这将更加高效地提升算法性能。
    
    ![截屏2023-04-07 09.22.13.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.22.13.png)
    
- 数据增强 **Data augmentation *ˌɔɡˌmɛnˈteɪʃ(ə)n*：这是一种用于图像和音频数据的技术，**通过对现有训练样本进行修改（如旋转、放大、缩小、改变对比度等），从而创造出新的训练样本**。数据增强能显著提高训练集的大小，提升算法性能。
    
    ![截屏2023-04-07 09.22.26.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.22.26.png)
    
    ![截屏2023-04-07 09.22.36.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.22.36.png)
    
    ![截屏2023-04-07 09.22.54.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.22.54.png)
    
    ![截屏2023-04-07 09.23.02.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.23.02.png)
    
- 数据合成 Artificial data synthesis *ˌɑrdəˈfɪʃ(ə)l  ˈsɪnθəsəs*：与数据增强不同，**数据合成是从头创建全新的训练样本，**而非通过修改现有样本。例如，通过使用计算机中的不同字体、颜色和对比度合成文字图像，以生成大量用于光学字符识别任务的训练样本。
    
    ![截屏2023-04-07 09.23.09.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.23.09.png)
    
    ![截屏2023-04-07 09.23.21.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.23.21.png)
    
    - 🔰问题：与 real data 对应的 synthetic data 是什么意思？通过软件生成的图片？比如从电脑中通过不同字体、叠加变形、灰度等等、自己生成全新的图片给模型识别吗？
        
        是的，您的理解是正确的。**在机器学习中，与实际数据（real data）相对的合成数据（synthetic data）指的是通过计算机程序生成的数据，而非直接从现实世界中收集的数据。合成数据的生成方法通常是基于一定的规则、模型或算法。**
        
        在上述课程示例中，合成数据是通过在计算机上使用不同字体、颜色和对比度生成的文字图像。这些合成图像可以用于训练光学字符识别（OCR）模型。通过合成数据生成，可以创建大量样本以供模型学习，从而提高模型性能。
        
- 数据驱动方法：传统的机器学习研究方法主要集中在改进算法，而在许多情况下，现有的算法（如线性回归、逻辑回归、神经网络等）已经非常优秀。因此，更关注数据驱动方法，如收集更多特定类型的数据、使用数据增强和数据合成，可能是提升算法性能的更有效途径。
- 迁移学习：在数据量有限且难以获取更多数据的情况下，迁移学习可以提升算法性能。其**核心思想是利用来自与目标任务相关但不完全相同的任务的数据**，在神经网络中对这些数据进行处理，以提高目标任务的算法性能。虽然并非所有任务都适用，但在适用的情况下，迁移学习可以非常强大。
    
    ![截屏2023-04-07 09.23.28.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.23.28.png)
    

> **一句话总结：**
错误分析→增加数据：选择算法表现不佳的特定数据、有针对的收集更多此类数据。
增加数据的方式：数据变形、数据合成、迁移学习
> 

## 转移学习：使用来自不同任务的数据：[Transfer learning: using data from a different task](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/ycgS5/transfer-learning-using-data-from-a-different-task)

这段文字讲述了迁移学习（Transfer Learning）的概念及其实现方法。迁移学习是一种在有限数据情况下提高模型性能的有效技巧。下面我们将详细讨论迁移学习的关键知识点：

- 迁移学习（Transfer Learning）：**我们使用一个预先训练好的模型（在大量数据集上训练得到的），并将其部分参数应用到新的任务中。**通过这种方式，新任务能够从预训练模型中获得的知识中受益。
    
    ![截屏2023-04-07 09.52.54.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.52.54.png)
    
- 迁移学习的两种方法：
    - 方法1：仅训练输出层参数（output layer）。保持从预训练模型中复制过来的参数固定，仅使用梯度下降或Adam优化算法更新输出层的权重；
    - 方法2：训练整个网络中的所有参数。使用从预训练模型中复制过来的参数作为初始值，然后使用梯度下降或Adam优化算法更新整个网络中的所有参数。
        
        ![截屏2023-04-07 09.53.03.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.53.03.png)
        
- 迁移学习的两个阶段：
    - **监督预训练（Supervised Pre-training）**：在一个大型数据集（如：ImageNet）上训练神经网络，学习到通用的特征表示。**迁移学习中预训练和微调的输入类型必须相同**。例如，如果最终任务是计算机视觉任务，那么预训练阶段的神经网络也必须是在相同类型的图像输入上训练得到的。
    - **微调（Fine-tuning）**：将预训练的神经网络参数应用到新任务中，并对网络参数进行进一步的优化。**如果可以从大型数据集（如一百万张图像）上获取预训练的神经网络，那么有时只需用较小的数据集（如一千张图像，甚至更少）进行微调**，就可以获得不错的结果。
    
    ![截屏2023-04-07 09.53.09.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_09.53.09.png)
    

> **一句话总结：**
Transfer Learning（GPT3）：预先训练好的模型，并将其部分参数应用到新的任务中。
两个阶段：预训练（大量数据训练）、微调（小数据微调参数）
> 

## 机器学习项目的完整周期：[Full cycle of a machine learning project](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/D1N6k/full-cycle-of-a-machine-learning-project)

在这段内容中，我们讨论了机器学习项目的完整周期。以下是关键知识点的概述：

- **项目范围**：确定要处理的问题和工作内容。例如，在这个例子中，要处理的问题是通过手机语音识别进行网络搜索。
- **数据收集**：确定需要哪些数据来训练机器学习系统，并收集音频和标签数据。
- **模型训练**：使用收集的数据训练语音识别系统，进行误差分析和迭代改进。此过程可能需要多次循环，收集更多或特定类型的数据以提高算法性能。
- **部署**：将训练好的模型部署到生产环境，使用户可以使用。
- **监控与维护**：部署后，持续监控系统性能，确保其稳定运行。如果性能下降，需要进行维护和优化。
- **生产部署中的数据利用**：从实际应用中获取的数据可以用于改进模型性能。
    
    ![截屏2023-04-07 10.01.49.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_10.01.49.png)
    

关于部署的详细说明：

- 将训练好的模型部署在一个推理服务器上，该**服务器负责调用模型进行预测**。
- 移动应用**程序通过API调用推理服务器**，将音频片段传递给服务器，服务器返回预测的文本。
- 根据应用程序的规模，可能需要进行大量软件工程工作，以确保推理服务器能够为大量用户提供可靠、高效的预测。
- **日志记录和监控对于检测模型性能下降和数据变化至关重要**。
    
    ![截屏2023-04-07 10.02.01.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_10.02.01.png)
    

MLOps（机器学习操作）是一个与部署和维护机器学习系统相关的领域，负责确保模型可靠、可扩展、有良好的日志记录，能够监控并在适当的时候进行更新。

在部署机器学习系统时，还需要关注伦理问题，这是许多应用中至关重要的话题。

> **一句话总结：**
机器学习完整周期：项目范围（问题）、数据收集、模型训练、部署（用户可用）、监控与维护、生产部署中的数据利用（再改善）
机器学习完整周期→部署：部署在服务器上、移动应用 API 调用、确保大量用户得到可靠预测、监控模型性能
> 

## 公平、偏见和道德：[Fairness, bias, and ethics](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/HYNX7/fairness-bias-and-ethics)

在这个课程中，讲述了关于机器学习中的公平性、偏见和伦理问题。以下是一些关键知识点：

- 机器学习对社会的影响：机器学习系统已经对全球数十亿人产生了影响，因此在开发机器学习系统时，我们需要关注这些系统的**公平性、偏见和伦理问题。**
    
    ![截屏2023-04-07 10.03.34.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_10.03.34.png)
    
    - 机器学习系统的潜在问题：**机器学习系统可能出现歧视性、有偏见的决策，**如歧视性招聘工具、面部识别系统偏向于特定肤色的人群、贷款批准系统的歧视性决策等。这些问题可能导致对某些群体造成伤害。
    - **伦理挑战**：确保机器学习系统的伦理性并非易事。尽管没有一个通用的“道德清单”，但可以遵循一些实践建议，以确保工作更加公平、无偏见和具有道德性。
        
        ![截屏2023-04-08 11.06.16.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_11.06.16.png)
        
- 实践建议：
    - **组建多样化团队(diverse team** *daɪˈvərs***)**：多样化的团队能更好地发现可能出现的问题，从而降低系统对特定群体造成伤害的可能性。
    - **遵循行业标准和指南(guidlines)**：了解并遵循你所在行业的相关伦理和公平性标准，确保你的工作符合行业要求。
    - **系统审计(audit system)**：在部署系统之前，对其进行审计，以确保已经识别并解决可能的问题，防止对某些群体造成伤害。
    - **制定缓解计划(mitigation plan** *ˌmɪdəˈɡeɪʃ(ə)n***)**：在部署之前制定一个应对可能问题的计划，确保在发生问题时能够迅速采取行动。
    - **持续监测**：在系统部署后，继续监控其可能带来的伤害，以便在发现问题时立即采取行动。
    
    ![截屏2023-04-07 10.04.01.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_10.04.01.png)
    

总之，在开发和部署机器学习系统时，我们应该充分考虑公平性、偏见和伦理问题。在某些情况下，这些问题可能比技术挑战更为重要。通过采用上述实践建议，我们可以努力确保我们的工作对社会产生积极的影响。

> **一句话总结：**
机器学习对社会的影响：公平、歧视、道德
实践建议：组件多样化团队、遵循行业标准和指南、系统审计、制定缓解计划、持续检测
> 

# 倾斜的数据集：**Skewed datasets (optional)**

---

## 倾斜数据集的错误指标：[Error metrics for skewed datasets](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/pjuBJ/error-metrics-for-skewed-datasets)

在这个例子中，我们讨论了**一个偏斜数据集的问题，即其中一个类（如罕见疾病）的样本数量远小于另一个类。**在这种情况下，**我们不能仅使用准确率（accuracy）作为评估指标，因为它可能会误导我们对分类器性能的判断。**

![截屏2023-04-07 10.05.34.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_10.05.34.png)

为了更好地评估分类器的性能，我们引入了两个指标：精确率（precision）和召回率（recall）。

- **精确率（Precision）**：精确率是指**在所有被分类为正类的样本中，实际上是正类的样本所占的比例。**换句话说，当我们的分类器预测一个样本为正类时，我们有多大把握认为这个预测是正确的。精确率的计算公式是：
    
    精确率 = True Positives / (True Positives + False Positives)
    
- **召回率（Recall）**：召回率是指在**所有实际上是正类的样本中，被正确分类为正类的样本所占的比例。**换句话说，我们的分类器能找到多少实际上是正类的样本。召回率的计算公式是：
    
    召回率 = True Positives / (True Positives + False Negatives)
    
    - 🔰记忆：**`Precision = [1,1]/合计i=1`**      `**Recall =[1,1]/合计j=1**`
    
    ![Predicted 纵轴预测值、Actural 横轴实际值；#所有预测为 1 的值:predicted positive=(1,1)+(0,1) #所有实际为 1 的值:actual positive=(1,1)+(1,0) ](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_10.05.50.png)
    
    Predicted 纵轴预测值、Actural 横轴实际值；#所有预测为 1 的值:predicted positive=(1,1)+(0,1) #所有实际为 1 的值:actual positive=(1,1)+(1,0) 
    
- 为了更好地理解精确率和召回率，我们可以构建一个混淆矩阵（Confusion Matrix），它是一个2x2的表格，其中包括四个部分：True Positives（TP，真正例）、True Negatives（TN，真反例）、False Positives（FP，假正例）和False Negatives（FN，假反例）。这四个部分分别代表：
    - 真正例（True Positives, TP）：实际为正类，预测为正类的样本数量。
    - 真反例（True Negatives, TN）：实际为反类，预测为反类的样本数量。
    - 假正例（False Positives, FP）：实际为反类，预测为正类的样本数量。
    - 假反例（False Negatives, FN）：实际为正类，预测为反类的样本数量。

通过计算精确率和召回率，我们可以更好地评估在偏斜数据集上的分类器性能。一个有用的分类器应该在精确率和召回率上都有较高的分数。在实际应用中，我们可能需要在精确率和召回率之间进行权衡，以获得最佳的分类器性能。这种权衡取决于我们的应用场景以及对于不同类型错误的容忍程度。

- 🔰问题：没懂什么意思、可以用实际简单例子说明吗？
    
    假设我们有一个关于乳腺癌诊断的分类器。在这里，正类是患有乳腺癌的患者，负类是没有乳腺癌的患者。
    
    我们将数据分为以下四个部分：
    
    1. 真阳性（TP，True Positive）：实际上患有乳腺癌，且分类器预测为阳性（正确）的患者数量。
    2. 假阳性（FP，False Positive）：实际上没有乳腺癌，但分类器错误地预测为阳性（错误）的患者数量。
    3. 真阴性（TN，True Negative）：实际上没有乳腺癌，且分类器预测为阴性（正确）的患者数量。
    4. 假阴性（FN，False Negative）：实际上患有乳腺癌，但分类器错误地预测为阴性（错误）的患者数量。
    
    现在，让我们用这些概念来解释精确率和召回率：
    
    - **精确率（Precision）**：在所有被分类为阳性（患有乳腺癌）的患者中，实际上确实患有乳腺癌的患者所占的比例。精确率 = 真阳性 /（真阳性 + 假阳性）。精确率实际上衡量了分类器预测阳性的可靠性。
    
    例如，**如果**分类器诊断了**100名患者患有乳腺癌，其中实际上确实患有乳腺癌的患者有70名，那么精确率就是70%。**
    
    - **召回率（Recall）**：在所有实际上患有乳腺癌的患者中，被分类器正确诊断为患有乳腺癌的患者所占的比例。召回率 = 真阳性 /（真阳性 + 假阴性）。召回率实际上衡量了分类器识别出真正阳性样本的能力。
    
    例如，**如果**实际上有**100名患者患有乳腺癌，而分类器只诊断出了其中的80名患者，那么召回率就是80%。**
    

> **一句话总结：**
偏斜数据集的问题：即其中一个类的样本数量远小于另一个类。
精确率：**`Precision = [1,1]/合计i=1`**     
召回率：`**Recall =[1,1]/合计j=1**`
> 

## 衡量精确率和召回率：[Trading off precision and recall](https://www.coursera.org/learn/advanced-learning-algorithms/lecture/42TEG/trading-off-precision-and-recall)

本视频讲解了学习算法中的**精确度（Precision）和召回率（Recall）之间的权衡**。以下是关键知识点：

- 精确度和召回率定义：
    - 精确度（Precision）：真阳性的数量除以预测阳性的总数。
    - 召回率（Recall）：真阳性的数量除以实际阳性的总数。
- 对于学习算法，通常需要在精确度和召回率之间进行权衡。通过调整阈值，可以在这两者之间找到适当的平衡点。
- 阈值的调整：
    - 提高阈值：增加精确度，降低召回率。
    - 降低阈值：降低精确度，提高召回率。
    
    ![截屏2023-04-07 10.07.05.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_10.07.05.png)
    
- F1分数（F1 Score）是一种将精确度和召回率结合起来的度量方法，它为不同算法提供了一个统一的评价指标。F1分数的计算公式为：
    - F1 = 2 * (Precision * Recall) / (Precision + Recall)
    
    ![截屏2023-04-07 10.07.23.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-07_10.07.23.png)
    

> **一句话总结：**
阈值↑ ：精确率↑ 、召回率↓
阈值↓ ：精确率↓ 、召回率↑
 综合度量  `**F1 Score = 2*(P*R)/(P+R)**`
> 

## [Practice Lab: Advice for Applying Machine Learning](https://www.coursera.org/learn/advanced-learning-algorithms/programming/ygSag/practice-lab-advice-for-applying-machine-learning)

![截屏2023-04-08 15.50.53.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_15.50.53.png)

![截屏2023-04-08 15.53.28.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_15.53.28.png)

![截屏2023-04-08 15.55.30.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_15.55.30.png)

![截屏2023-04-08 15.56.06.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_15.56.06.png)

![截屏2023-04-08 15.57.30.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_15.57.30.png)

![截屏2023-04-08 16.06.28.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_16.06.28.png)

![截屏2023-04-08 16.05.21.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_16.05.21.png)

![截屏2023-04-08 16.08.14.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_16.08.14.png)

![截屏2023-04-08 16.14.26.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_16.14.26.png)

```python
#Iterate to find optimal regularization value
tf.random.set_seed(1234)
lambdas = [0.0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3]
models=[None] * len(lambdas)

for i in range(len(lambdas)):
    lambda_ = lambdas[i]
    models[i] =  Sequential(
        [
            Dense(120, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),
            Dense(40, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),
            Dense(classes, activation = 'linear')
        ]
    )
    models[i].compile(
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        optimizer=tf.keras.optimizers.Adam(0.01),
    )

    models[i].fit(
        X_train,y_train,
        epochs=1000
    )
    print(f"Finished lambda = {lambda_}")
```

![截屏2023-04-08 16.34.20.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_16.34.20.png)

![截屏2023-04-08 16.35.41.png](2%203%E9%AB%98%E7%BA%A7%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%EF%BC%9A%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE%205fbd005fa6f34e48945fa6eba57fccf1/%25E6%2588%25AA%25E5%25B1%258F2023-04-08_16.35.41.png)